# 第三章 神经网络

## 本章概要

1. 复习感知机，如下图，

   <img src="images/%E7%AC%AC%E4%B8%89%E7%AB%A0%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20211209194101167.png" alt="image-20211209194101167" style="zoom:70%;" />

   当$b+w_1x_1+w_2x_2≤0$​时，y值为0，反之y值为1，为了简化该式子，引入一个函数h（x）来表示这种分情况的动作，即$y=h(b+w_1x_1+w_2x_2)$​，当参数整体值≤0时y取0，反之取1。h(x)函数会将输入信号的总和转换为输出信号，这种函数即称为激活函数。

2. 一般而言，“朴素感知机”是指单层网络，指的是激活函数使用了**阶跃函数**的模型。“多层感知机”是指神经网络，即使用sigmoid函数等**平滑的激活函数**的多层网络。

3. 阶跃函数和sigmoid函数的共同性质：输入小时，输出接近0，随着输入增大，输出向1靠近。其次，输出信号的值都在0到1之间。同样，都是非线性函数（如果是线性的，神经网络的层数就失去了意义）

4. ReLU函数在输入大于0时，直接输出该值；在输入小于等于0时，输出0

5. 例如如下的神经网络，使用矩阵乘法，可将第一层的加权和表示成$A^{(1)}=XW^{(1)}+B^{(1)}$

   <img src="images/%E7%AC%AC%E4%B8%89%E7%AB%A0%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20211209194114337.png" alt="image-20211209194114337" style="zoom:67%;" />

   其中，$w^{(1)}_{12}$表示第一层权重里前一层的第二个节点到后一层第一个节点的权重值

   <img src="images/%E7%AC%AC%E4%B8%89%E7%AB%A0%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20211209194124376.png" alt="image-20211209194124376" style="zoom:67%;" />

   ```python
   #前向传播
   def init_network():
       network = {}
       network['W1'] = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])
       network['b1'] = np.array([0.1, 0.2, 0.3])
       network['W2'] = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])
       network['b2'] = np.array([0.1, 0.2])
       network['W3'] = np.array([[0.1, 0.3], [0.2, 0.4]])
       network['b3'] = np.array([0.1, 0.2])
       return network
   def forward(network, x):
       W1, W2, W3 = network['W1'], network['W2'], network['W3']
       b1, b2, b3 = network['b1'], network['b2'], network['b3']
       a1 = np.dot(x, W1) + b1
       z1 = sigmoid(a1)
       a2 = np.dot(z1, W2) + b2
       z2 = sigmoid(a2)
       a3 = np.dot(z2, W3) + b3
       y = identity_function(a3)
       return y
   network = init_network()
   x = np.array([1.0, 0.5])
   y = forward(network, x)
   ```

6. 输出层的设计：神经网络可以用在分类问题和回归问题上，不过需要根据情况改变输出层的激活函数。一般而言，回归问题用恒等函数，分类问题用softmax函数。恒等函数不用解释，softmax函数如下所示,yk表示第k个神经元的输出
   $$
   y_k=\frac{\exp(a_k)}{\sum_{i=1}^{n}\exp(a_i)}
   $$
   上式存在溢出问题，因为指数运算太大，可以做如下改进，这里的C可以使用任何值，但是为了防止溢出，一般会使用输入信号中的最大值
   $$
   y_k=\frac{C\exp(a_k)}{C\sum_{i=1}^{n}\exp(a_i)}=\frac{\exp(a_k+\log C)}{C\sum_{i=1}^{n}\exp(a_i+\log C)}
   $$

7. softmax函数的输出是0.0到1.0之间的实数，且softmax函数的输出值的总和是1。这是softmax函数的一个重要性质，因为有了这个性质，我们才可以把softmax函数的输出解释为“概率”。即便使用了softmax函数，各个元素之间的大小关系也不会改变。这是因为指数函数是单调递增函数，所以在分类问题时，为了减轻计算量可省略该函数

## 代码实现

使用MNIST数据集做手写图像分类

```python
#备用工具函数
def sigmoid(x):
    return 1 / (1 + np.exp(-x))
def softmax(a):
    c = np.max(a)
    exp_a = np.exp(a - c) # 溢出对策
    sum_exp_a = np.sum(exp_a)
    y = exp_a / sum_exp_a
    return y
```

```python
#下载数据集
try:
    import urllib.request
except ImportError:
    raise ImportError('You should use Python 3.x')
import os.path
import gzip
import pickle
import os
import numpy as np


url_base = 'http://yann.lecun.com/exdb/mnist/'
key_file = {
    'train_img':'train-images-idx3-ubyte.gz',
    'train_label':'train-labels-idx1-ubyte.gz',
    'test_img':'t10k-images-idx3-ubyte.gz',
    'test_label':'t10k-labels-idx1-ubyte.gz'
}
#代码文件路径
dataset_dir ="代码文件路径"
save_file = dataset_dir + "/mnist.pkl"

train_num = 60000
test_num = 10000
img_dim = (1, 28, 28)
img_size = 784


def _download(file_name):
    file_path = dataset_dir + "/" + file_name
    
    if os.path.exists(file_path):
        return

    print("Downloading " + file_name + " ... ")
    urllib.request.urlretrieve(url_base + file_name, file_path)
    print("Done")
    
def download_mnist():
    for v in key_file.values():
       _download(v)
        
def _load_label(file_name):
    file_path = dataset_dir + "/" + file_name
    
    print("Converting " + file_name + " to NumPy Array ...")
    with gzip.open(file_path, 'rb') as f:
            labels = np.frombuffer(f.read(), np.uint8, offset=8)
    print("Done")
    
    return labels

def _load_img(file_name):
    file_path = dataset_dir + "/" + file_name
    
    print("Converting " + file_name + " to NumPy Array ...")    
    with gzip.open(file_path, 'rb') as f:
            data = np.frombuffer(f.read(), np.uint8, offset=16)
    data = data.reshape(-1, img_size)
    print("Done")
    
    return data
    
def _convert_numpy():
    dataset = {}
    dataset['train_img'] =  _load_img(key_file['train_img'])
    dataset['train_label'] = _load_label(key_file['train_label'])    
    dataset['test_img'] = _load_img(key_file['test_img'])
    dataset['test_label'] = _load_label(key_file['test_label'])
    
    return dataset

def init_mnist():
    download_mnist()
    dataset = _convert_numpy()
    print("Creating pickle file ...")
    with open(save_file, 'wb') as f:
        pickle.dump(dataset, f, -1)
    print("Done!")

def _change_one_hot_label(X):
    T = np.zeros((X.size, 10))
    for idx, row in enumerate(T):
        row[X[idx]] = 1
        
    return T
    

def load_mnist(normalize=True, flatten=True, one_hot_label=False):
    """读入MNIST数据集
    
    Parameters
    ----------
    normalize : 将图像的像素值正规化为0.0~1.0
    one_hot_label : 
        one_hot_label为True的情况下，标签作为one-hot数组返回
        one-hot数组是指[0,0,1,0,0,0,0,0,0,0]这样的数组
    flatten : 是否将图像展开为一维数组
    
    Returns
    -------
    (训练图像, 训练标签), (测试图像, 测试标签)
    """
    if not os.path.exists(save_file):
        init_mnist()
        
    with open(save_file, 'rb') as f:
        dataset = pickle.load(f)
    
    if normalize:
        for key in ('train_img', 'test_img'):
            dataset[key] = dataset[key].astype(np.float32)
            dataset[key] /= 255.0
            
    if one_hot_label:
        dataset['train_label'] = _change_one_hot_label(dataset['train_label'])
        dataset['test_label'] = _change_one_hot_label(dataset['test_label'])
    
    if not flatten:
         for key in ('train_img', 'test_img'):
            dataset[key] = dataset[key].reshape(-1, 1, 28, 28)

    return (dataset['train_img'], dataset['train_label']), (dataset['test_img'], dataset['test_label']) 


if __name__ == '__main__':
    init_mnist()
```

```python
#神经网络输入有784个神经元，输出有10个
#有2个隐藏层，第1个隐藏层有50个神经元，第2个隐藏层有100个神经元
def get_data():
    (x_train, t_train), (x_test, t_test) = \
        load_mnist(normalize=True, flatten=True, one_hot_label=False)
    return x_test, t_test
#读入保存在pickle文件sample_weight.pkl中的学习到的权重参数A
def init_network():
    with open("sample_weight.pkl", 'rb') as f:
        network = pickle.load(f)
    return network
def predict(network, x):
    W1, W2, W3 = network['W1'], network['W2'], network['W3']
    b1, b2, b3 = network['b1'], network['b2'], network['b3']
    a1 = np.dot(x, W1) + b1
    z1 = sigmoid(a1)
    a2 = np.dot(z1, W2) + b2
    z2 = sigmoid(a2)
    a3 = np.dot(z2, W3) + b3
    y = softmax(a3)
    return y
```

```python
#在学习好的权重数据打包成pkl文件可以直接用时
x, t = get_data()
network = init_network()
accuracy_cnt = 0

batch_size = 100 # 批数量，批处理

for i in range(0, len(x), batch_size):
    x_batch = x[i:i+batch_size]
    y_batch = predict(network, x_batch)
    p = np.argmax(y_batch, axis=1)
    accuracy_cnt += np.sum(p == t[i:i+batch_size])
print("Accuracy:" + str(float(accuracy_cnt) / len(x)))

```

